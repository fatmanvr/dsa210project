{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ac48f92",
   "metadata": {},
   "source": [
    "# Machine Learning Analysis: Predictability of AI Art Popularity\n",
    "\n",
    "In my earlier EDA and hypothesis testing, individual metadata variables (such as tool, style, platform, and region) did not show statistically significant effects on popularity.  \n",
    "In this notebook, I test whether **multivariate machine learning models** can extract predictive signal from metadata alone, or whether popularity is fundamentally driven by unobserved factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87e048a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96438d0e",
   "metadata": {},
   "source": [
    "## 1. Feature Engineering\n",
    "\n",
    "To enrich the input space without using visual content, I derive additional features from existing metadata:\n",
    "\n",
    "- Temporal features (Year, Month, recency indicators)\n",
    "- Cyclic encodings for seasonal patterns\n",
    "- Simple binary flags derived from metadata\n",
    "\n",
    "to capture potential hidden structure while remaining fully interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b37981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ai_generated_art_trends_2024.csv\")\n",
    "\n",
    "# ----- DATE FEATURES -----\n",
    "df[\"Creation_Date\"] = pd.to_datetime(df[\"Creation_Date\"], errors=\"coerce\")\n",
    "df[\"Year\"]  = df[\"Creation_Date\"].dt.year\n",
    "df[\"Month\"] = df[\"Creation_Date\"].dt.month\n",
    "\n",
    "df[\"is_recent\"] = (df[\"Year\"] >= 2023).astype(int)\n",
    "\n",
    "def month_to_season(m):\n",
    "    if pd.isna(m): return np.nan\n",
    "    if m in [12,1,2]: return \"Winter\"\n",
    "    if m in [3,4,5]: return \"Spring\"\n",
    "    if m in [6,7,8]: return \"Summer\"\n",
    "    return \"Fall\"\n",
    "\n",
    "df[\"Season\"] = df[\"Month\"].apply(month_to_season)\n",
    "\n",
    "# cyclic month\n",
    "df[\"month_sin\"] = np.sin(2*np.pi*df[\"Month\"]/12)\n",
    "df[\"month_cos\"] = np.cos(2*np.pi*df[\"Month\"]/12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de64b9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----FREQUENCY/RARITY FEATURES------\n",
    "\n",
    "cat_cols = [\"Art_Style\",\"Tools_Used\",\"Platform\",\"Region\",\"Art_Genre\",\"Medium\"]\n",
    "\n",
    "for c in cat_cols:\n",
    "    freq = df[c].value_counts()\n",
    "    df[f\"{c}_freq\"] = df[c].map(freq)\n",
    "    df[f\"{c}_is_rare\"] = (df[f\"{c}_freq\"] <= 50).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cd0c78",
   "metadata": {},
   "source": [
    "## 2. Regression Task: Predicting Popularity Score\n",
    "\n",
    "At first, I formulate the problem as a regression task, where the goal is to predict the numerical popularity score of an artwork from metadata features, and to test whether a linear relationship exists between metadata and popularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "762bf350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1436.5059680175225\n",
      "R2  : -0.007570819100202408\n"
     ]
    }
   ],
   "source": [
    "y = df[\"Popularity_Score\"]\n",
    "X = df.drop(columns=[\"Popularity_Score\", \"Artwork_ID\", \"Artist_Name\"], errors=\"ignore\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "cat_cols = X.select_dtypes(include=\"object\").columns\n",
    "num_cols = X.select_dtypes(include=\"number\").columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        ]), cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", Ridge(alpha=1.0))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "pred = pipe.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2  :\", r2_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7f7818",
   "metadata": {},
   "source": [
    "### Regression Results Interpretation\n",
    "\n",
    "The regression model yields a negative R² value, indicating that it performs worse than simply predicting the mean popularity score for all artworks.\n",
    "\n",
    "This result suggests that: Linear relationships between metadata and popularity are weak or nonexistent, and popularity is likely influenced by complex, non-linear, or unobserved factors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee0fe2a",
   "metadata": {},
   "source": [
    "## 3. Non-linear Regression: Random Forest Regressor\n",
    "\n",
    "Since linear regression fails to capture meaningful patterns, I apply a Random Forest Regressor to model potential non-linear interactions between metadata features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe9b98b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE: 1463.141653703112\n",
      "Random Forest R2  : -0.04528197261842948\n"
     ]
    }
   ],
   "source": [
    "rf_pipe = Pipeline(steps=[\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", RandomForestRegressor(\n",
    "        n_estimators=200,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "rf_pipe.fit(X_train, y_train)\n",
    "\n",
    "rf_pred = rf_pipe.predict(X_test)\n",
    "\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_pred))\n",
    "rf_r2   = r2_score(y_test, rf_pred)\n",
    "\n",
    "print(\"Random Forest RMSE:\", rf_rmse)\n",
    "print(\"Random Forest R2  :\", rf_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043c0743",
   "metadata": {},
   "source": [
    "### Random Forest Regression Results\n",
    "\n",
    "Random Forest did not improve performance because the R² score remains negative, and prediction error stays high.\n",
    "Since an ensemble model still fails, the issue is likely insufficient information in metadata, not model choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dffc6a7",
   "metadata": {},
   "source": [
    "## 4. From Regression to Classification\n",
    "\n",
    "Predicting the exact popularity score is hard and noisy, so I reframe the task as a binary classification problem, and ask\n",
    "**Can metadata distinguish high-performing vs low-performing artworks?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e7b346",
   "metadata": {},
   "source": [
    "## 5. Classification Models: High vs. Low Popularity\n",
    "\n",
    "I define two classes:\n",
    "**High popularity:** popularity score ≥ median, and **Low popularity:** popularity score < median\n",
    "\n",
    "and I train and evaluate:\n",
    "- Logistic Regression (baseline classifier)\n",
    "- Random Forest Classifier (non-linear classifier)\n",
    "\n",
    "Model performance is evaluated using: Accuracy, ROC-AUC, Confusion Matrix and classification metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf6f57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression ===\n",
      "Accuracy: 0.5065\n",
      "ROC-AUC : 0.4987565\n",
      "Confusion matrix:\n",
      " [[501 499]\n",
      " [488 512]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5066    0.5010    0.5038      1000\n",
      "           1     0.5064    0.5120    0.5092      1000\n",
      "\n",
      "    accuracy                         0.5065      2000\n",
      "   macro avg     0.5065    0.5065    0.5065      2000\n",
      "weighted avg     0.5065    0.5065    0.5065      2000\n",
      "\n",
      "\n",
      "=== Random Forest Classifier ===\n",
      "Accuracy: 0.516\n",
      "ROC-AUC : 0.5097195000000001\n",
      "Confusion matrix:\n",
      " [[535 465]\n",
      " [503 497]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5154    0.5350    0.5250      1000\n",
      "           1     0.5166    0.4970    0.5066      1000\n",
      "\n",
      "    accuracy                         0.5160      2000\n",
      "   macro avg     0.5160    0.5160    0.5158      2000\n",
      "weighted avg     0.5160    0.5160    0.5158      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---- 1) TARGET: High vs Low popularity -----\n",
    "median_pop = df[\"Popularity_Score\"].median()\n",
    "df[\"popularity_class\"] = (df[\"Popularity_Score\"] >= median_pop).astype(int)\n",
    "\n",
    "y = df[\"popularity_class\"]\n",
    "X = df.drop(columns=[\"popularity_class\", \"Popularity_Score\"], errors=\"ignore\")\n",
    "X = X.drop(columns=[\"Artwork_ID\", \"Artist_Name\"], errors=\"ignore\")\n",
    "\n",
    "# ---- 2) SPLIT (stratify important)-----\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ----- 3) PREPROCESSING -----\n",
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "numeric_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "])\n",
    "\n",
    "categorical_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_pipe, num_cols),\n",
    "        (\"cat\", categorical_pipe, cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ---- 4) MODEL 1: Logistic Regression -----\n",
    "log_clf = Pipeline(steps=[\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", LogisticRegression(\n",
    "        solver=\"saga\",\n",
    "        max_iter=20000,\n",
    "        C=0.1,\n",
    "        tol=1e-3, \n",
    "    ))\n",
    "])\n",
    "\n",
    "log_clf.fit(X_train, y_train)\n",
    "log_pred = log_clf.predict(X_test)\n",
    "log_proba = log_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== Logistic Regression ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, log_pred))\n",
    "print(\"ROC-AUC :\", roc_auc_score(y_test, log_proba))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, log_pred))\n",
    "print(classification_report(y_test, log_pred, digits=4))\n",
    "\n",
    "# ---- 5) MODEL 2: Random Forest -----\n",
    "rf_clf = Pipeline(steps=[\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "rf_proba = rf_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n=== Random Forest Classifier ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, rf_pred))\n",
    "print(\"ROC-AUC :\", roc_auc_score(y_test, rf_proba))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, rf_pred))\n",
    "print(classification_report(y_test, rf_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76860371",
   "metadata": {},
   "source": [
    "### Classification Results Interpretation\n",
    "\n",
    "Both Logistic Regression and Random Forest achieved ROC-AUC values close to 0.50, which is near random guessing.\n",
    "\n",
    "This indicates that even after simplifying the target into two classes, the available metadata does not provide enough signal to separate high vs low popularity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43480809",
   "metadata": {},
   "source": [
    "## Overall Machine Learning Conclusion\n",
    "\n",
    "Across regression and classification experiments, machine learning models consistently fail to predict or distinguish artwork popularity using metadata alone.\n",
    "\n",
    "This result confirms that:\n",
    "- Popularity is not driven by observable metadata features such as style, tool, platform, or region.\n",
    "- Engagement is likely dominated by latent factors not captured in the dataset, including visual aesthetics, platform recommendation systems, and social dynamics.\n",
    "\n",
    "Importantly, these negative results are consistent with prior hypothesis testing and provide strong evidence about the **limits of predictability** given the available data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
