{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ac48f92",
   "metadata": {},
   "source": [
    "# Machine Learning Analysis: Predictability of AI Art Popularity\n",
    "\n",
    "In my earlier EDA and hypothesis testing, individual metadata variables (such as tool, style, platform, and region) did not show statistically significant effects on popularity.  \n",
    "In this notebook, I test whether **multivariate machine learning models** can extract predictive signal from metadata alone, or whether popularity is fundamentally driven by unobserved factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87e048a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96438d0e",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "To enrich the input space without using visual content, I derive additional features from existing metadata:\n",
    "\n",
    "- Temporal features (Year, Month, recency indicators)\n",
    "- Cyclic encodings for seasonal patterns\n",
    "- Simple binary flags derived from metadata\n",
    "\n",
    "to capture potential hidden structure while remaining fully interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b37981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ai_generated_art_trends_2024.csv\")\n",
    "\n",
    "# ----- DATE FEATURES -----\n",
    "df[\"Creation_Date\"] = pd.to_datetime(df[\"Creation_Date\"], errors=\"coerce\")\n",
    "df[\"Year\"]  = df[\"Creation_Date\"].dt.year\n",
    "df[\"Month\"] = df[\"Creation_Date\"].dt.month\n",
    "\n",
    "df[\"is_recent\"] = (df[\"Year\"] >= 2023).astype(int)\n",
    "\n",
    "def month_to_season(m):\n",
    "    if pd.isna(m): return np.nan\n",
    "    if m in [12,1,2]: return \"Winter\"\n",
    "    if m in [3,4,5]: return \"Spring\"\n",
    "    if m in [6,7,8]: return \"Summer\"\n",
    "    return \"Fall\"\n",
    "\n",
    "df[\"Season\"] = df[\"Month\"].apply(month_to_season)\n",
    "\n",
    "# cyclic month\n",
    "df[\"month_sin\"] = np.sin(2*np.pi*df[\"Month\"]/12)\n",
    "df[\"month_cos\"] = np.cos(2*np.pi*df[\"Month\"]/12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de64b9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----FREQUENCY/RARITY FEATURES------\n",
    "\n",
    "cat_cols = [\"Art_Style\",\"Tools_Used\",\"Platform\",\"Region\",\"Art_Genre\",\"Medium\"]\n",
    "\n",
    "for c in cat_cols:\n",
    "    freq = df[c].value_counts()\n",
    "    df[f\"{c}_freq\"] = df[c].map(freq)\n",
    "    df[f\"{c}_is_rare\"] = (df[f\"{c}_freq\"] <= 50).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32165d5a",
   "metadata": {},
   "source": [
    "Despite incorporating temporal, cyclic, and rarity-based features, we see later that model performance does not improve, suggesting that these engineered features still fail to capture the underlying drivers of popularity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cd0c78",
   "metadata": {},
   "source": [
    "## Regression Task: Predicting Popularity Score\n",
    "\n",
    "At first, I formulate the problem as a regression task, where the goal is to predict the numerical popularity score of an artwork from metadata features, and to test whether a linear relationship exists between metadata and popularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "762bf350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1436.5059680175225\n",
      "R2  : -0.007570819100202408\n"
     ]
    }
   ],
   "source": [
    "y = df[\"Popularity_Score\"]\n",
    "X = df.drop(columns=[\"Popularity_Score\", \"Artwork_ID\", \"Artist_Name\"], errors=\"ignore\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "cat_cols = X.select_dtypes(include=\"object\").columns\n",
    "num_cols = X.select_dtypes(include=\"number\").columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        ]), cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", Ridge(alpha=1.0))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "pred = pipe.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2  :\", r2_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7f7818",
   "metadata": {},
   "source": [
    "### Regression Results Interpretation\n",
    "\n",
    "The regression model yields a negative R² value, indicating that it performs worse than simply predicting the mean popularity score for all artworks.\n",
    "\n",
    "This result suggests that: Linear relationships between metadata and popularity are weak or nonexistent, and popularity is likely influenced by complex, non-linear, or unobserved factors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee0fe2a",
   "metadata": {},
   "source": [
    "## Non-linear Regression: Random Forest Regressor\n",
    "\n",
    "Since linear regression fails to capture meaningful patterns, I apply a Random Forest Regressor to model potential non-linear interactions between metadata features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe9b98b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE: 1463.141653703112\n",
      "Random Forest R2  : -0.04528197261842948\n"
     ]
    }
   ],
   "source": [
    "rf_pipe = Pipeline(steps=[\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", RandomForestRegressor(\n",
    "        n_estimators=200,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "rf_pipe.fit(X_train, y_train)\n",
    "\n",
    "rf_pred = rf_pipe.predict(X_test)\n",
    "\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_pred))\n",
    "rf_r2   = r2_score(y_test, rf_pred)\n",
    "\n",
    "print(\"Random Forest RMSE:\", rf_rmse)\n",
    "print(\"Random Forest R2  :\", rf_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043c0743",
   "metadata": {},
   "source": [
    "### Random Forest Regression Results\n",
    "\n",
    "Random Forest did not improve performance because the R² score remains negative, and prediction error stays high.\n",
    "Since an ensemble model still fails, the issue is likely insufficient information in metadata, not model choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dffc6a7",
   "metadata": {},
   "source": [
    "## From Regression to Classification\n",
    "\n",
    "Predicting the exact popularity score is hard and noisy, so I reframe the task as a binary classification problem, and ask\n",
    "**Can metadata distinguish high-performing vs low-performing artworks?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e7b346",
   "metadata": {},
   "source": [
    "## Classification Models: High vs. Low Popularity\n",
    "\n",
    "I define two classes:\n",
    "**High popularity:** popularity score ≥ median, and **Low popularity:** popularity score < median\n",
    "\n",
    "and I train and evaluate:\n",
    "- Logistic Regression (baseline classifier)\n",
    "- Random Forest Classifier (non-linear classifier)\n",
    "\n",
    "Model performance is evaluated using: Accuracy, ROC-AUC, Confusion Matrix and classification metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8cf6f57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression ===\n",
      "Accuracy: 0.506\n",
      "ROC-AUC : 0.49875849999999994\n",
      "Confusion matrix:\n",
      " [[500 500]\n",
      " [488 512]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5061    0.5000    0.5030      1000\n",
      "           1     0.5059    0.5120    0.5089      1000\n",
      "\n",
      "    accuracy                         0.5060      2000\n",
      "   macro avg     0.5060    0.5060    0.5060      2000\n",
      "weighted avg     0.5060    0.5060    0.5060      2000\n",
      "\n",
      "\n",
      "=== Random Forest Classifier ===\n",
      "Accuracy: 0.516\n",
      "ROC-AUC : 0.5097195000000001\n",
      "Confusion matrix:\n",
      " [[535 465]\n",
      " [503 497]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5154    0.5350    0.5250      1000\n",
      "           1     0.5166    0.4970    0.5066      1000\n",
      "\n",
      "    accuracy                         0.5160      2000\n",
      "   macro avg     0.5160    0.5160    0.5158      2000\n",
      "weighted avg     0.5160    0.5160    0.5158      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---- 1) TARGET: High vs Low popularity -----\n",
    "median_pop = df[\"Popularity_Score\"].median()\n",
    "df[\"popularity_class\"] = (df[\"Popularity_Score\"] >= median_pop).astype(int)\n",
    "\n",
    "y = df[\"popularity_class\"]\n",
    "X = df.drop(columns=[\"popularity_class\", \"Popularity_Score\"], errors=\"ignore\")\n",
    "X = X.drop(columns=[\"Artwork_ID\", \"Artist_Name\"], errors=\"ignore\")\n",
    "\n",
    "# ---- 2) SPLIT (stratify important)-----\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ----- 3) PREPROCESSING -----\n",
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "numeric_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "])\n",
    "\n",
    "categorical_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_pipe, num_cols),\n",
    "        (\"cat\", categorical_pipe, cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ---- 4) MODEL 1: Logistic Regression -----\n",
    "log_clf = Pipeline(steps=[\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", LogisticRegression(\n",
    "        solver=\"saga\",\n",
    "        max_iter=20000,\n",
    "        C=0.1,\n",
    "        tol=1e-3, \n",
    "    ))\n",
    "])\n",
    "\n",
    "log_clf.fit(X_train, y_train)\n",
    "log_pred = log_clf.predict(X_test)\n",
    "log_proba = log_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== Logistic Regression ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, log_pred))\n",
    "print(\"ROC-AUC :\", roc_auc_score(y_test, log_proba))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, log_pred))\n",
    "print(classification_report(y_test, log_pred, digits=4))\n",
    "\n",
    "# ---- 5) MODEL 2: Random Forest -----\n",
    "rf_clf = Pipeline(steps=[\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "rf_proba = rf_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n=== Random Forest Classifier ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, rf_pred))\n",
    "print(\"ROC-AUC :\", roc_auc_score(y_test, rf_proba))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, rf_pred))\n",
    "print(classification_report(y_test, rf_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76860371",
   "metadata": {},
   "source": [
    "### Classification Results Interpretation\n",
    "\n",
    "Both Logistic Regression and Random Forest achieved ROC-AUC values close to 0.50, which is near random guessing.\n",
    "\n",
    "This indicates that even after simplifying the target into two classes, the available metadata does not provide enough signal to separate high vs low popularity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43480809",
   "metadata": {},
   "source": [
    "## Machine Learning Conclusion for Dataset 1 and Additional Machine Learning Experiment\n",
    "\n",
    "Across regression and classification experiments, machine learning models consistently fail to predict or distinguish artwork popularity using metadata alone.\n",
    "\n",
    "Unlike the previous dataset, this dataset contains direct user interaction metrics\n",
    "such as views, likes, comments, and shares, and allows testing whether direct engagement metrics contain predictive signal beyond descriptive metadata\n",
    "\n",
    "We therefore evaluate whether these features can predict the overall engagement score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9725bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Ridge Regression ===\n",
      "RMSE: 0.2520875396662983\n",
      "R2  : -0.005725867425898423\n",
      "\n",
      "=== Random Forest Regressor ===\n",
      "RMSE: 0.258758757848567\n",
      "R2  : -0.059661062728380454\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"AI_Generated_Art_Popularity.csv\")\n",
    "y = df2[\"Engagement_Score\"]\n",
    "X = df2.drop(columns=[\"Engagement_Score\"])\n",
    "\n",
    "numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "categorical_features = X.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "# Preprocessing\n",
    "numeric_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_pipe, numeric_features),\n",
    "    (\"cat\", categorical_pipe, categorical_features)\n",
    "])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -------- Ridge Regression --------\n",
    "ridge = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", Ridge(alpha=1.0))\n",
    "])\n",
    "\n",
    "ridge.fit(X_train, y_train)\n",
    "pred_ridge = ridge.predict(X_test)\n",
    "\n",
    "print(\"=== Ridge Regression ===\")\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, pred_ridge)))\n",
    "print(\"R2  :\", r2_score(y_test, pred_ridge))\n",
    "\n",
    "# -------- Random Forest --------\n",
    "rf = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", RandomForestRegressor(\n",
    "        n_estimators=300,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"\\n=== Random Forest Regressor ===\")\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, pred_rf)))\n",
    "print(\"R2  :\", r2_score(y_test, pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8803d6c",
   "metadata": {},
   "source": [
    "### Interpretation of Initial Engagement Score Regression Results\n",
    "\n",
    "The initial regression models yield an RMSE of approximately 0.25 and a slightly negative R² value.\n",
    "A negative R² indicates that the models perform worse than a simple mean-based predictor,\n",
    "suggesting a weak alignment between the selected features and the engagement score.\n",
    "\n",
    "This outcome is not due to a modeling or implementation error.\n",
    "Instead, it likely reflects a mismatch between the target variable and the available features.\n",
    "Since the engagement score is already a normalized or aggregated function of interaction metrics\n",
    "(such as views, likes, comments, and shares), attempting to predict it using these same variables\n",
    "resembles reverse engineering and limits the learnable signal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09552f8",
   "metadata": {},
   "source": [
    "## Baseline Comparison Using Dummy Regressor\n",
    "To assess whether regression models learn meaningful patterns, a Dummy\n",
    "Regressor is used as a baseline that predicts the mean engagement score.\n",
    "Model performance is compared against this baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9df20fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dummy Regressor ===\n",
      "RMSE: 0.25137079555161135\n",
      "R2  : -1.4967734849102854e-05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "dummy = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", DummyRegressor(strategy=\"mean\"))\n",
    "])\n",
    "\n",
    "dummy.fit(X_train, y_train)\n",
    "pred_dummy = dummy.predict(X_test)\n",
    "\n",
    "print(\"=== Dummy Regressor ===\")\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, pred_dummy)))\n",
    "print(\"R2  :\", r2_score(y_test, pred_dummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd9a81d",
   "metadata": {},
   "source": [
    "Regression models do not outperform a simple dummy baseline,\n",
    "indicating that the available features do not provide meaningful\n",
    "predictive information for engagement score estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c7b40c",
   "metadata": {},
   "source": [
    "## Classification Models – Binary Popularity Prediction\n",
    "In addition to regression, popularity prediction is reformulated as a\n",
    "binary classification task, where artworks are labeled as high or low\n",
    "popularity based on a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "250f3f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"High_Engagement\"] = (\n",
    "    df2[\"Engagement_Score\"] > df2[\"Engagement_Score\"].median()\n",
    ").astype(int)\n",
    "\n",
    "y_cls = df2[\"High_Engagement\"]\n",
    "X_cls = df2.drop(columns=[\"Engagement_Score\", \"High_Engagement\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0bb95834",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_cls, y_cls, test_size=0.2, random_state=42, stratify=y_cls\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6583e80",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "Logistic Regression is applied as a probabilistic linear classifier to\n",
    "establish a baseline for binary popularity prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e22958bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression ===\n",
      "Accuracy: 0.483\n",
      "ROC-AUC : 0.4722730018280658\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.50      0.49       503\n",
      "           1       0.48      0.46      0.47       497\n",
      "\n",
      "    accuracy                           0.48      1000\n",
      "   macro avg       0.48      0.48      0.48      1000\n",
      "weighted avg       0.48      0.48      0.48      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_clf = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", LogisticRegression(\n",
    "        solver=\"saga\",\n",
    "        max_iter=20000,\n",
    "        C=0.1,\n",
    "        tol=1e-3\n",
    "    ))\n",
    "])\n",
    "\n",
    "log_clf.fit(X_train, y_train)\n",
    "pred_log = log_clf.predict(X_test)\n",
    "proba_log = log_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== Logistic Regression ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_log))\n",
    "print(\"ROC-AUC :\", roc_auc_score(y_test, proba_log))\n",
    "print(classification_report(y_test, pred_log))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbf5e7f",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n",
    "A Random Forest Classifier is used to model non-linear decision boundaries\n",
    "and compare performance against the linear classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0699df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest Classifier ===\n",
      "Accuracy: 0.469\n",
      "ROC-AUC : 0.45917853042709544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.48      0.48       503\n",
      "           1       0.47      0.46      0.46       497\n",
      "\n",
      "    accuracy                           0.47      1000\n",
      "   macro avg       0.47      0.47      0.47      1000\n",
      "weighted avg       0.47      0.47      0.47      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_clf = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "pred_rf = rf_clf.predict(X_test)\n",
    "proba_rf = rf_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== Random Forest Classifier ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_rf))\n",
    "print(\"ROC-AUC :\", roc_auc_score(y_test, proba_rf))\n",
    "print(classification_report(y_test, pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafcd80b",
   "metadata": {},
   "source": [
    "Both Logistic Regression and Random Forest achieve accuracy and ROC-AUC values\n",
    "close to random guessing, suggesting that high and low engagement levels\n",
    "cannot be reliably distinguished using the current feature set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00aee81",
   "metadata": {},
   "source": [
    "## Overall Conclusion\n",
    "\n",
    "Across two different datasets and multiple machine learning formulations,\n",
    "the models consistently fail to achieve meaningful predictive performance.\n",
    "\n",
    "In the first dataset, which relies primarily on descriptive metadata\n",
    "such as style, tool, platform, region, and time, neither regression nor\n",
    "classification models outperform simple baselines. This indicates that\n",
    "artwork popularity cannot be reliably inferred from high-level attributes alone.\n",
    "\n",
    "In the second dataset, despite the inclusion of interaction-related variables,\n",
    "regression models do not improve over a dummy predictor and classification\n",
    "models perform close to random guessing. This suggests that engagement and\n",
    "popularity are likely driven by latent factors—such as visual aesthetics,\n",
    "platform-specific algorithms, or social dynamics—that are not captured in\n",
    "the available features.\n",
    "\n",
    "Overall, these results highlight the limitations of metadata-driven approaches\n",
    "and emphasize the importance of richer content-based or network-level information\n",
    "for predicting popularity and engagement in AI-generated art.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
